# 第一章 大模型简介

## 1.概述

### 	1.发展历程

语言建模的研究始于20世纪90年代，但那时采用的统计学习方法不能满足理解复杂语言规则的需求。

在2003年，Bengio首次将深度学习的思想融入语言模型中，2018年左右，Transformer架构的神经网络模型被引入，自此，大语言模型的时代到来。

### 	2.大语言模型的概念

**大语言模型（英文：Large Language Model，缩写LLM）是一种人工智能模型，皆在理解和生成人类语言。**

大语言模型包含数百亿（或更多）参数的语言模型，然后通过大量文本数据训练就可以更好理解人类语言并且作出答复。

现在大语言模型的极限已达万亿参数（GPT-4），这其中一个杰出应用就是**ChatGPT**，它的出现可以说是又一次科技革命。

​	**LLM的应用与影响**

LLM的出现不仅影响了**自然语言处理**领域，而且还带动了**信息检索**领域和**计算机视觉**领域。

这两者也可以通过类似于LLM的大数据训练和多参数来使其更能理解人类的需求。在未来，这种训练人工智能的思路会应用到各个领域。

## 2.大模型的能力、特点

### 1.大模型的能力

1.1**涌现能力**

涌现能力就是我们常说的量变引起质变，随着参数越来越多和训练数据的增加，LLM的性能也提升了许多。

下面是三个典型的LLM涌现能力：

- 上下文学习：可以理解上下文并给出答复。
- 指令遵循：也就是指令微调，可以在指令形式化描述的时候执行未见过的任务，且表现良好。
- 逐步推理：采用“思维链”，可以利用包含中间推理步骤的提示完成任务。

1.2**作为基座模型支持多元应用**

在2021年，斯坦福大学等多所高校的研究人员提出了**基座模型（foundation model）**的概念，这更清晰地描述了之前学界所称的预训练模型的作用。这是一种全新的AI技术范式，借助于海量无标注数据的训练，获得可以适用于大量下游任务的大模型（单模态或者多模态）。这样，多个应用可以只依赖于一个或少数几个大模型进行统一建设。

1.3**支持对话作为统一入口的能力**

### 2.大模型的特点

1. 巨大规模
2. 预训练和微调
3. 上下文感知
4. 多语言支持
5. 多模态支持
6. 涌现能力
7. 多领域应用
8. 伦理和风险问题

## 3.常见大模型

1. ChatGPT
2. GPT-4
3. Claude系列
4. PaLM系列
5. 文心一言
6. 讯飞星火
7. LLaMA系列
8. GLM系列
9. 通义千问
10. Baichuan系列

7-10是开源的LLM大模型。

# 4.LangChain

**LangChain 框架是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程**。

**LangChain核心组件**

LangChian 作为一个大语言模型开发框架，可以将 LLM 模型（对话模型、embedding模型等）、向量数据库、交互层 Prompt、外部知识、外部代理工具整合到一起，进而可以自由构建 LLM 应用。 LangChain 主要由以下 6 个核心模块组成:

- **模型输入/输出（Model I/O）**：与语言模型交互的接口
- **数据连接（Data connection）**：与特定应用程序的数据进行交互的接口
- **链（Chains）**：将组件组合实现端到端应用。
- **记忆（Memory）**：用于链的多次运行之间持久化应用程序状态；
- **代理（Agents）**：扩展模型的推理能力。用于复杂的应用的调用序列；
- **回调（Callbacks）**：扩展模型的推理能力。用于复杂的应用的调用序列；

# 第二章 调用大模型API

## 1.基础概念

### 1.1Prompt

Prompt 最初是 NLP（自然语言处理）研究者为下游任务设计出来的一种任务专属的输入模板，类似于一种任务（例如：分类，聚类等）会对应一种 Prompt。在 ChatGPT 推出并获得大量应用之后，Prompt 开始被推广为给大模型的所有输入。即，我们每一次访问大模型的输入为一个 Prompt，而大模型给我们的返回结果则被称为 Completion。

### 1.2Temperature

LLM 生成是具有随机性的，在模型的顶层通过选取不同预测概率的预测结果来生成最后的结果。我们一般可以通过控制 Temperature 参数来控制 LLM 生成结果的随机性与创造性。

Temperature 一般取值在 0~1 之间，当取值较低接近0时，预测的随机性会较低，产生更保守、可预测的文本，不太可能生成意想不到或不寻常的词。当取值较高接近1时，预测的随机性会较高，所有词被选择的可能性更大，会产生更有创意、多样化的文本，更有可能生成不寻常或意想不到的词。

### 1.3System Prompt

System Prompt 是随着 ChatGPT API 开放并逐步得到大量使用的一个新兴概念，事实上，它并不在大模型本身训练中得到体现，而是大模型服务方为提升用户体验所设置的一种策略。

具体来说，在使用 ChatGPT API 时，你可以设置两种 Prompt：一种是 System Prompt，该种 Prompt 内容会在整个会话过程中持久地影响模型的回复，且相比于普通 Prompt 具有更高的重要性；另一种是 User Prompt，这更偏向于咱们平时的 Prompt，即需要模型做出回复的输入。

## 2.调用ChatGPT

将OpenAI的API设置为全局变量后调用出现以下错误

![image-20231119120518290](C:\Users\龚曦\AppData\Roaming\Typora\typora-user-images\image-20231119120518290.png)

## 3.调用百度文心

![image-20231119120144793](C:\Users\龚曦\AppData\Roaming\Typora\typora-user-images\image-20231119120144793.png)

调用成功。

但是在用langchain调用的时候出现了问题，

![image-20231119122717952](C:\Users\龚曦\AppData\Roaming\Typora\typora-user-images\image-20231119122717952.png)

配置没有问题，但就是说api_key出现了问题。

## 4.调用讯飞星火

还未开始，等有时间会补充上去。